# PaddleOCRv5 ONNX Inference - R\&D Summary Document

## 1. M·ª•c ti√™u nghi√™n c·ª©u

X√¢y d·ª±ng l·∫°i pipeline PaddleOCRv5 inference ho√†n to√†n b·∫±ng ONNX, kh√¥ng ph·ª• thu·ªôc v√†o Paddle framework, ƒë·ªÉ ph·ª•c v·ª• nh·∫≠n d·∫°ng ch·ªØ t·ª´ ·∫£nh (image to text). Nghi√™n c·ª©u m√¥ h√¨nh detection-recognition c·ªßa PaddleOCRv5, hi·ªÉu r√µ ki·∫øn tr√∫c, chu·∫©n h√≥a input/output, c·∫•u h√¨nh YAML, v√† lo·∫°i b·ªè th√†nh ph·∫ßn classifier trong qu√° tr√¨nh t·ªëi ∆∞u h√≥a cho inference.

## 2. T·ªïng quan pipeline

Pipeline inference chia th√†nh hai giai ƒëo·∫°n:

```
Input Image
  ‚Üí Detection Preprocessing
  ‚Üí Detection ONNX (DB Algorithm)
  ‚Üí DB Postprocessing
  ‚Üí Crop Text Regions
  ‚Üí Recognition Preprocessing
  ‚Üí Recognition ONNX (SVTR_LCNet)
  ‚Üí CTC Decoding
  ‚Üí Final Text
```

> Ghi ch√∫: Kh√¥ng c√≥ b∆∞·ªõc classification ‚Äì text orientation ƒë∆∞·ª£c x·ª≠ l√Ω trong b∆∞·ªõc crop b·∫±ng logic h√¨nh h·ªçc.

## 2.1 Detection Phase
M·ª•c ti√™u c·ªßa b∆∞·ªõc n√†y l√† x√°c ƒë·ªãnh v√πng c√≥ ch·ª©a ch·ªØ trong ·∫£nh ƒë·∫ßu v√†o, d∆∞·ªõi d·∫°ng box 4 ƒëi·ªÉm.
## 2.1.1 Detection Preprocessing
Tr∆∞·ªõc khi ƒë∆∞a ·∫£nh v√†o model ONNX, ·∫£nh c·∫ßn ƒë∆∞·ª£c bi·∫øn ƒë·ªïi v·ªÅ format v√† th·ªëng nh·∫•t scale ƒë·ªÉ kh·ªõp v·ªõi m√¥ h√¨nh ƒë√£ training.
C√°c b∆∞·ªõc c·ª• th·ªÉ: 
1. Resize ·∫£nh v·ªÅ k√≠ch th∆∞·ªõc c·ªë ƒë·ªãnh [640, 640]

‚úÖ What:
Chuy·ªÉn ·∫£nh v·ªÅ k√≠ch th∆∞·ªõc c·ªë ƒë·ªãnh 640x640 pixel, b·∫•t k·ªÉ input ban ƒë·∫ßu l√† g√¨.

‚ùì Why ‚Äì L√Ω do s√¢u:

PP-OCRv5_mobile_det s·ª≠ d·ª•ng:
Backbone: PPLCNetV3
Detection Head: DB (Differentiable Binarization)
Ref: https://github.com/PaddlePaddle/PaddleOCR/blob/main/configs/det/PP-OCRv5/PP-OCRv5_mobile_det.yml

a. Ki·∫øn tr√∫c PP-OCRv5_mobile_det y√™u c·∫ßu ·∫£nh ƒë·∫ßu v√†o c·ªë ƒë·ªãnh [3, 640, 640]:

C√°c layer nh∆∞ Conv2D, DepthwiseConv, BatchNorm c√≥ weight ƒë∆∞·ª£c training theo k√≠ch th∆∞·ªõc n√†y, v√† ONNX export ƒë√£ c·ªë ƒë·ªãnh input shape.
    Khi export sang ONNX (ho·∫∑c static inference engine), to√†n b·ªô kernel shape, stride, padding, input/output tensor shape ƒë∆∞·ª£c hard-code.
    N·∫øu b·∫°n ƒë∆∞a ·∫£nh k√≠ch th∆∞·ªõc kh√°c v√†o:
    Layer Conv2D kh√¥ng matching shape ‚Üí ONNX runtime b√°o l·ªói.

Ho·∫∑c model ‚Äúch·∫°y ƒë∆∞·ª£c‚Äù nh∆∞ng output feature map b·ªã l·ªách t·∫ßng ‚Üí DB Head decode sai v√πng ch·ªØ.
N·∫øu ƒë∆∞a input sai k√≠ch th∆∞·ªõc, model s·∫Ω b√°o l·ªói shape mismatch, ho·∫∑c t·∫°o ra output DB map sai t·ªâ l·ªá v·ªõi ·∫£nh g·ªëc.
Ngo√†i ra, postprocess (decode box) ph·ª• thu·ªôc v√†o t·ª∑ l·ªá gi·ªØa ·∫£nh v√† DB map, n√™n n·∫øu shape l·ªách s·∫Ω g√¢y l·ªói ho·∫∑c k·∫øt qu·∫£ sai ho√†n to√†n.

üìå b. DB Head ph·ª• thu·ªôc v√†o t·ª∑ l·ªá kh√¥ng gian gi·ªØa ·∫£nh v√† output map
DB head kh√¥ng tr·ª±c ti·∫øp predict bounding box, m√† sinh ra c√°c map nh·ªã ph√¢n:
    Binary map (text vs background)
    Threshold map
    Approximate binarized map
C√°c map n√†y c√≥ shape c·ªë ƒë·ªãnh, v√≠ d·ª• [160 √ó 160] (do backbone stride = 4)
N·∫øu ·∫£nh input kh√¥ng ƒë√∫ng [640 √ó 640] th√¨:
M·ªói pixel tr√™n map kh√¥ng c√≤n t∆∞∆°ng ·ª©ng ch√≠nh x√°c v·ªõi v√πng ·∫£nh g·ªëc
‚Üí Decode box b·ªã sai v·ªã tr√≠ v√† scale
üß† Do ƒë√≥, resize ƒë√∫ng shape l√† b·∫Øt bu·ªôc ƒë·ªÉ ƒë·∫£m b·∫£o DB map ph·∫£n √°nh ch√≠nh x√°c kh√¥ng gian ·∫£nh g·ªëc.

üìå c. Kh√°c v·ªõi Recognition, ·ªü b∆∞·ªõc Detection kh√¥ng c·∫ßn gi·ªØ nguy√™n aspect ratio khi resize ·∫£nh

Vi·ªác resize tr·ª±c ti·∫øp thay v√¨ padding gi·ªØ t·ªâ l·ªá l√† m·ªôt l·ª±a ch·ªçn thi·∫øt k·∫ø trong PaddleOCR v√¨:
üîÑ Detection ho·∫°t ƒë·ªông ·ªü c·∫•p ƒë·ªô to√†n ·∫£nh (global layout), ch·ª© kh√¥ng c·∫ßn ƒë·ªô ch√≠nh x√°c pixel-level nh∆∞ recognition. Khi resize m√©o, c√°c ƒëo·∫°n vƒÉn b·∫£n v·∫´n gi·ªØ ƒë∆∞·ª£c t∆∞∆°ng quan kh√¥ng gian ƒë·ªß ƒë·ªÉ model nh·∫≠n bi·∫øt v√πng c√≥ ch·ªØ.
üß† Ki·∫øn tr√∫c DB head kh√¥ng ph·ª• thu·ªôc tuy·ªát ƒë·ªëi v√†o aspect ratio. N√≥ h·ªçc d·ª±a tr√™n h√¨nh d·∫°ng v√πng li√™n k·∫øt (connected region) h∆°n l√† chi ti·∫øt k√≠ch th∆∞·ªõc ch√≠nh x√°c c·ªßa t·ª´ng k√Ω t·ª±.
‚ö° Padding gi·ªØ t·ªâ l·ªá tuy gi√∫p tr√°nh m√©o h√¨nh, nh∆∞ng l√†m ch·∫≠m inference:
      G√¢y th√™m thao t√°c padding/tracking padding size.
      C·∫ßn x·ª≠ l√Ω ng∆∞·ª£c padding sau khi decode box.
      Ph·ª©c t·∫°p h∆°n n·∫øu ch·∫°y batch-size >1 v·ªõi nhi·ªÅu t·ªâ l·ªá ·∫£nh kh√°c nhau.
‚úÖ PaddleOCR ch·∫•p nh·∫≠n trade-off: m·ªôt m·ª©c m√©o nh·∫π v·∫´n ƒë·∫£m b·∫£o detect ƒë·ªß t·ªët v·ªõi ƒëa s·ªë vƒÉn b·∫£n th·∫≠t, trong khi gi√∫p tƒÉng t·ªëc ƒë√°ng k·ªÉ cho inference.

2. Convert sang float32 (n·∫øu ·∫£nh l√† uint8)

‚úÖ What:
Chuy·ªÉn ki·ªÉu d·ªØ li·ªáu t·ª´ uint8 (·∫£nh ƒë·∫ßu v√†o t·ª´ OpenCV) sang float32 ‚Äî ƒë·ªãnh d·∫°ng m√† m√¥ h√¨nh y√™u c·∫ßu.

‚ùì Why ‚Äì L√Ω do s√¢u:

a. ONNX Runtime ch·ªâ ch·∫•p nh·∫≠n input ki·ªÉu float32

M√¥ h√¨nh ƒë∆∞·ª£c hu·∫•n luy·ªán v√† export v·ªõi c√°c tensor float32.
N·∫øu ƒë∆∞a v√†o uint8, ONNX Runtime s·∫Ω:
    B√°o l·ªói kh√¥ng kh·ªõp ki·ªÉu
    Ho·∫∑c cast ng·∫ßm ‚Üí d·ªÖ g√¢y bug ho·∫∑c cho k·∫øt qu·∫£ sai

b. √âp ki·ªÉu float32 l√† ti·ªÅn ƒë·ªÅ b·∫Øt bu·ªôc tr∆∞·ªõc khi normalize

Vi·ªác normalize sau ƒë√≥ (img / 255.0, tr·ª´ mean, chia std) y√™u c·∫ßu input l√† float32.
N·∫øu th·ª±c hi·ªán tr√™n uint8:
    K·∫øt qu·∫£ ph√©p chia c√≥ th·ªÉ tr·∫£ v·ªÅ float64 (g√¢y l·ªói khi ƒë∆∞a v√†o model)
    Ho·∫∑c chia sai do ph√©p to√°n nguy√™n ‚Üí ra to√†n s·ªë 0

3. Chu·∫©n h√≥a b·∫±ng ImageNet mean/std

mean = [0.485, 0.456, 0.406]  
std  = [0.229, 0.224, 0.225]

Ref for mean and std: https://github.com/PaddlePaddle/PaddleOCR/blob/main/configs/det/PP-OCRv5/PP-OCRv5_mobile_det.yml

2 b∆∞·ªõc chu·∫©n h√≥a ·∫£nh ƒë·∫ßu v√†o:
Scale pixel t·ª´ [0, 255] ‚Üí [0.0, 1.0]
Ref: https://pytorch.org/vision/stable/transforms.html#torchvision.transforms.Normalize
Normalize ·∫£nh b·∫±ng c√°ch tr·ª´ mean v√† chia std c·ªßa ImageNet, nh·∫±m ƒë∆∞a pixel ƒë·∫ßu v√†o v·ªÅ ph√¢n ph·ªëi c√≥ mean ‚âà 0 v√† std ‚âà 1 tr√™n t·ª´ng channel, ƒë√∫ng nh∆∞ m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c pretrain.

‚ùì Why ‚Äì L√Ω do s√¢u:

a. Backbone (PPLCNetV3) ƒë∆∞·ª£c pretrain tr√™n ImageNet:
C√°c tr·ªçng s·ªë layer (conv, bn, relu) trong PPLCNetV3 ƒë∆∞·ª£c hu·∫•n luy·ªán v·ªõi input c√≥ mean/std nh∆∞ tr√™n.
N·∫øu kh√¥ng chu·∫©n h√≥a ƒë√∫ng, input s·∫Ω c√≥ ph√¢n ph·ªëi kh√°c ‚Üí
    Feature map b·ªã l·ªách to√†n di·ªán
    C√°c filter ƒë√£ h·ªçc t·ª´ d·ªØ li·ªáu g·ªëc (ImageNet) kh√¥ng c√≤n kh·ªõp
‚Üí Gi·ªëng nh∆∞ ƒë∆∞a ·∫£nh ‚Äúnhi·ªÖu s√°ng‚Äù ho·∫∑c ‚Äúng∆∞·ª£c m√†u‚Äù v√†o model ‚Üí m√¥ h√¨nh ph·∫£n ·ª©ng sai ho·∫∑c cho k·∫øt qu·∫£ r√°c.

b. Normalize gi√∫p lo·∫°i b·ªè nhi·ªÖu √°nh s√°ng v√† ƒë·ªô t∆∞∆°ng ph·∫£n
·∫¢nh g·ªëc c√≥ th·ªÉ b·ªã t·ªëi/s√°ng, nhi·ªÖu, ƒë·ªô t∆∞∆°ng ph·∫£n cao th·∫•p kh√¥ng ·ªïn ƒë·ªãnh
Vi·ªác normalize gi√∫p:
M·ªói pixel mang th√¥ng tin t∆∞∆°ng ƒë·ªëi, kh√¥ng tuy·ªát ƒë·ªëi
M√¥ h√¨nh t·∫≠p trung v√†o bi√™n, c·∫°nh, h√¨nh kh·ªëi (shape) ‚Äî th·ª© m√† DB head c·∫ßn ƒë·ªÉ ph√¢n bi·ªát v√πng c√≥ ch·ªØ hay kh√¥ng

c. Tr√°nh sai l·ªách s·ªë h·ªçc v√† tƒÉng ·ªïn ƒë·ªãnh khi inference

Gi√° tr·ªã pixel nh·ªè (‚âà ¬±1) sau normalize gi√∫p tr√°nh:
Overflow trong t√≠nh to√°n float
Gradient explode/vanish (n·∫øu d√πng backward debug)
Sai l·ªách h·∫≠u x·ª≠ l√Ω box n·∫øu scale ·∫£nh b·ªã l·ªách

4. Chuy·ªÉn ·∫£nh t·ª´ [H, W, C] ‚Üí [C, H, W]

‚úÖ What:
ƒê·ªïi th·ª© t·ª± chi·ªÅu d·ªØ li·ªáu ·∫£nh t·ª´ format m·∫∑c ƒë·ªãnh c·ªßa OpenCV ([H, W, C]) sang format chu·∫©n tensor [C, H, W] m√† model y√™u c·∫ßu.

‚ùì Why ‚Äì L√Ω do s√¢u:

a. H·∫ßu h·∫øt framework deep learning (Paddle, PyTorch, ONNX) ƒë·ªÅu expect input tensor ·ªü d·∫°ng:

[N, C, H, W]
(v·ªõi N: batch size, C: s·ªë channel, H, W: chi·ªÅu cao & chi·ªÅu r·ªông)

b. V√¨ sao Conv2D c·∫ßn channel C ƒë·ª©ng ƒë·∫ßu?
C√°c l·ªõp convolution (Conv2D) ho·∫°t ƒë·ªông theo c·∫•u tr√∫c:
For each channel c:
    Output += Input[c] * Kernel[c]
Vi·ªác ƒë∆∞a channel l√™n ƒë·∫ßu gi√∫p framework:
    Truy c·∫≠p k√™nh hi·ªáu qu·∫£ h∆°n trong memory (data locality t·ªët h∆°n)
    D·ªÖ d√†ng chia t√°ch per-channel filter khi optimize
    H·ªó tr·ª£ batch operation qua chi·ªÅu N (batch) ph√≠a tr∆∞·ªõc

c. N·∫øu gi·ªØ nguy√™n [H, W, C] ‚Üí ONNX s·∫Ω l·ªói ngay
Conv2D layer ƒë·∫ßu ti√™n s·∫Ω expect input shape [1, 3, 640, 640]
N·∫øu b·∫°n ƒë∆∞a [1, 640, 640, 3] ‚Üí ONNX Runtime b√°o l·ªói shape mismatch

d. Ngo√†i ra, m·ªôt s·ªë backend inference kh√¥ng t·ª± b√°o l·ªói r√µ
V·ªõi TensorRT, TVM ho·∫∑c custom engine: n·∫øu kh√¥ng reshape ƒë√∫ng [C, H, W], b·∫°n c√≥ th·ªÉ b·ªã:
    Silent failure: ·∫£nh b·ªã swap m√†u (RGB ‚Üî BGR)
    Output r√°c nh∆∞ng kh√¥ng l·ªói
    Debug kh√≥ v√¨ kh√¥ng bi·∫øt do format hay model

5. Th√™m batch dimension

‚úÖ What:
Th√™m m·ªôt chi·ªÅu ·ªü ƒë·∫ßu tensor ƒë·ªÉ chuy·ªÉn ·∫£nh t·ª´ [C, H, W] ‚Üí [1, C, H, W] (batch size = 1).

‚ùì Why ‚Äì L√Ω do s√¢u:

a. ONNX model y√™u c·∫ßu input c√≥ batch dimension:
C√°c m√¥ h√¨nh ONNX, bao g·ªìm PP-OCRv5_mobile_det, lu√¥n khai b√°o input v·ªõi shape [N, C, H, W]
N·∫øu b·∫°n ƒë∆∞a ·∫£nh thi·∫øu batch dimension ([3, 640, 640]), ONNX Runtime s·∫Ω:
    B√°o l·ªói Invalid input shape
    Ho·∫∑c √©p reshape ng·∫ßm ‚Üí g√¢y ra bug ng·∫ßm, kh√≥ debug

b. Chu·∫©n b·ªã cho batch inference:
Vi·ªác gi·ªØ c·∫•u tr√∫c batch-ready cho ph√©p d·ªÖ d√†ng m·ªü r·ªông v·ªÅ sau, ch·∫°y nhi·ªÅu ·∫£nh m·ªôt l√∫c m√† kh√¥ng c·∫ßn refactor pipeline.

Input shape ch√≠nh x√°c y√™u c·∫ßu:

[1, 3, 640, 640]
    1 ‚Üí batch size
    3 ‚Üí RGB
    640 √ó 640 ‚Üí spatial dimension

N·∫øu sai b·∫•t k·ª≥ chi·ªÅu n√†o:
Thi·∫øu batch	-> NNX Runtime b√°o l·ªói Invalid shape
Channel ‚â† 3	-> Conv layer kh√¥ng kh·ªõp weight ‚Üí l·ªói ho·∫∑c output r√°c
Size ‚â† 640x640 -> Output feature map sai ‚Üí DB map sai ‚Üí box sai

üìå Trong PaddleOCR, batch dimension ƒë∆∞·ª£c th√™m t·ª± ƒë·ªông ·ªü t·∫ßng `loader:`.  
Tuy nhi√™n, khi vi·∫øt pipeline inference ONNX ri√™ng, b·∫°n **ph·∫£i th√™m th·ªß c√¥ng** batch `[1, C, H, W]`, n·∫øu kh√¥ng s·∫Ω g·∫∑p l·ªói shape.

## 3. Th√†nh ph·∫ßn chi ti·∫øt

### 3.1 Detection Model (PP-OCRv5\_mobile\_det)

* **Ki·∫øn tr√∫c ch√≠nh**: DB (Differentiable Binarization)
* **Backbone**: PPLCNetV3, scale=0.75
* **Neck**: RSEFPN, 96 k√™nh, shortcut=True
* **Head**: DBHead, k=50, fix\_nan=True
* **Input**: \[1, 3, 640, 640]
* **Output**: Probability map \[1, 1, H, W]

#### V√¨ sao ch·ªçn DB:

* Ph√π h·ª£p v·ªõi b√†i to√°n segment v√πng text (thay v√¨ detect box c·ª©ng)
* K·∫øt qu·∫£ ra d·∫°ng mask ‚Üí d·ªÖ postprocess th√†nh box ch√≠nh x√°c

### 3.2 Recognition Model (PP-OCRv5\_mobile\_rec)

* **Ki·∫øn tr√∫c ch√≠nh**: SVTR\_LCNet
* **Backbone**: PPLCNetV3, scale=0.95
* **Head**: MultiHead (CTCHead + NRTRHead)
* **SVTR Neck**: dims=120, depth=2, hidden\_dims=120
* **Input**: \[1, 3, 48, variable-width]
* **Output**: Sequence \[1, T, vocab\_size]
* **Gi·ªõi h·∫°n ƒë·ªô d√†i**: max\_text\_length = 25

#### V√¨ sao d√πng SVTR\_LCNet:

* K·∫øt h·ª£p CNN (LCNet) v·ªõi self-attention (SVTR) ‚Üí nh·∫π, ch√≠nh x√°c
* Ph√π h·ª£p thi·∫øt b·ªã mobile, inference nhanh

### 3.3 Text Orientation Handling

* Kh√¥ng d√πng classification model
* G√≥c xoay ƒë∆∞·ª£c x·ª≠ l√Ω trong h√†m `get_rotate_crop_image()`
* Logic: N·∫øu box c√≥ height > 1.5 \* width ‚Üí t·ª± ƒë·ªông xoay d·ªçc

## 4. X·ª≠ l√Ω ·∫£nh v√† c·∫•u h√¨nh YAML

### 4.1 Detection Preprocessing

* Resize v·ªÅ \[3, 640, 640], scale theo t·ªâ l·ªá ·∫£nh g·ªëc
* Normalize theo ImageNet:

  ```yaml
  
  scale: 1./255.
  mean: [0.485, 0.456, 0.406]
  std:  [0.229, 0.224, 0.225]
  ```

### 4.2 Recognition Preprocessing

* Resize chi·ªÅu cao = 48px, width bi·∫øn ƒë·ªïi theo t·ªâ l·ªá ·∫£nh (min = 320)
* Normalize: (pixel / 255 - 0.5) / 0.5 ‚Üí range \[-1, 1]
* Padding b√™n ph·∫£i n·∫øu width ch∆∞a ƒë·ªß

### 4.3 Postprocessing Detection (DBPostProcess)

```yaml
thresh: 0.3
box_thresh: 0.6
max_candidates: 1000
unclip_ratio: 1.5
```

### 4.4 Postprocessing Recognition (CTCLabelDecode)

* D√πng CTC decoding ƒë·ªÉ t·∫°o chu·ªói k√Ω t·ª± t·ª´ x√°c su·∫•t frame
* Dictionary: `ppocrv5_dict.txt`
* H·ªó tr·ª£ ti·∫øng Trung, Nh·∫≠t, Anh, k√Ω t·ª± ƒë·∫∑c bi·ªát

## 5. C·∫•u h√¨nh hu·∫•n luy·ªán v√† kh·∫£ nƒÉng m·ªü r·ªông

### Detection Training (theo YAML)

* Optimizer: Adam (lr=0.001)
* Epochs: 500, Cosine LR
* Loss: DBLoss (Œ±=5, Œ≤=10)

### Recognition Training

* Optimizer: Adam (lr=0.0005)
* Epochs: 75, Cosine LR
* Loss: MultiLoss (CTCLoss + NRTRLoss)

### Batch Size

* Detection: 1 (eval)
* Recognition: 128 (eval)

## 6. Ph√¢n t√≠ch ƒëi·ªÉm m·∫°nh / h·∫°n ch·∫ø

### ƒêi·ªÉm m·∫°nh:

* Lightweight, t·ªëc ƒë·ªô nhanh, ch√≠nh x√°c t·ªët
* Kh√¥ng ph·ª• thu·ªôc Paddle khi convert sang ONNX
* C√≥ th·ªÉ ch·∫°y ho√†n to√†n b·∫±ng `onnxruntime` + `numpy`

### H·∫°n ch·∫ø:

* Kh√¥ng c√≥ stage classification ‚Üí ch∆∞a x·ª≠ l√Ω t·ªët text nghi√™ng ng∆∞·ª£c
* SVTR m·∫∑c ƒë·ªãnh d√πng dict g·ªëc Trung Qu·ªëc ‚Äì c·∫ßn thay dict n·∫øu mu·ªën d√πng ti·∫øng Vi·ªát
* Width recognition ph·∫£i >=320px ‚Üí ·∫£nh nh·ªè d·ªÖ b·ªã pad tr·∫Øng

## 7. Ki·∫øn tr√∫c th∆∞ m·ª•c g·ª£i √Ω

```
project_root/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ det_model.onnx
‚îÇ   ‚îî‚îÄ‚îÄ rec_model.onnx
‚îú‚îÄ‚îÄ dict/ppocrv5_dict.txt
‚îú‚îÄ‚îÄ pipeline/
‚îÇ   ‚îú‚îÄ‚îÄ preprocess.py
‚îÇ   ‚îú‚îÄ‚îÄ detect.py
‚îÇ   ‚îú‚îÄ‚îÄ crop.py
‚îÇ   ‚îú‚îÄ‚îÄ recognize.py
‚îÇ   ‚îî‚îÄ‚îÄ postprocess.py
‚îú‚îÄ‚îÄ main.py
‚îî‚îÄ‚îÄ README.md
```

## 8. Ph·ª• l·ª•c

### 8.1 Th∆∞ vi·ªán ph·ª• thu·ªôc

```bash
opencv-python
numpy
onnxruntime
shapely
pyclipper
matplotlib (optional)
Pillow (optional)
```

### 8.2 File c·∫•u h√¨nh YAML ch√≠nh

* det/det\_pp-ocrv5.yml
* rec/rec\_pp-ocrv5.yml

### 8.3 M√¥ t·∫£ dictionary k√Ω t·ª±

* `ppocrv5_dict.txt`: G·ªìm >7000 k√Ω t·ª±: ch·ªØ Trung, Nh·∫≠t, Latin, s·ªë, k√Ω hi·ªáu, kho·∫£ng tr·∫Øng

---

**Ng∆∞·ªùi th·ª±c hi·ªán:** \[T√™n b·∫°n]
**Ng√†y ho√†n t·∫•t:** \[DD/MM/YYYY]
**M·ª•c ƒë√≠ch:** L∆∞u tr·ªØ tri th·ª©c n·ªôi b·ªô, ph·ª•c v·ª• future dev/debug/integration
